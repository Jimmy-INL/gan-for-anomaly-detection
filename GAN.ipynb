{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dpb.bitbucket.io/reloading-modified-code-when-using-the-ipython-interactive-shell.html\n",
    "%load_ext autoreload\n",
    "%autoreload 1 # from now on, always reload those modules marked with %aimport before executing any Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import Activation, ZeroPadding2D\n",
    "\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_directory= \"C:\\\\Users\\\\Master\\\\Project\\\\Validator\\\\Python\\\\images\\\\docs\\\\valid\"\n",
    "train_directory=\"C:\\\\Users\\\\Master\\\\Project\\\\Validator\\\\Python\\\\images\\\\docs\\\\train\"\n",
    "\n",
    "input_shape         = (64, 64, 1)\n",
    "latent_shape        = (100, )\n",
    "n_filters           = [512, 256, 128, 64]\n",
    "filter_size         = 5\n",
    "strides             = 2\n",
    "gen_lr              = 2e-4 \n",
    "gen_beta1           = 0.8\n",
    "dis_lr              = 2e-4\n",
    "dis_beta1           = 0.8\n",
    "model_name          = \"my_model\"\n",
    "output_dirname      = 'output'\n",
    "stats_step_interval = 150\n",
    "epochs              = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use generator to extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 images belonging to 1 classes.\n",
      "Found 55 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory   = train_directory,       # this is the target directory\n",
    "    target_size = (64, 64, 1)[:-1],         # all images will be resized to 64x64\n",
    "    batch_size  = 64,\n",
    "    color_mode  = \"grayscale\",                    # We use a grayscale dataset\n",
    "    classes=[\"docs\"],\n",
    "    class_mode  = None                            # We do not need to get any label => Everything is healthy\n",
    ")  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    directory   = validation_directory,     # this is the target directory\n",
    "    target_size = (64, 64, 1)[:-1],         # all images will be resized to 64x64\n",
    "    batch_size  = 64,\n",
    "    color_mode  = \"grayscale\",              # We use a grayscale dataset\n",
    "    classes     = [\"docs\", \"other\"],        # {'docs': 0, 'other': 1} => Needs to be enforced\n",
    "    class_mode  = 'binary'                  # We want to have binary labels for validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_discriminator(input_shape, n_filters, filter_size, strides, dis_lr=2e-4,  dis_beta1=0.5, batch_norm_momentum=0.6):        \n",
    "\n",
    "        # discriminator input of size related to image size.\n",
    "        disc_input = Input(shape= input_shape, name='discriminator_input')\n",
    "\n",
    "        # Layer 2-5 - Conv Layers\n",
    "        for i, nb_filters in enumerate(n_filters[::-1]):  # List in reverse order\n",
    "            if (i == 0):\n",
    "                cnn = Conv2D(\n",
    "                        filters= nb_filters,\n",
    "                        kernel_size= filter_size,\n",
    "                        strides= strides,\n",
    "                        padding=\"same\",\n",
    "                        kernel_regularizer=l2(.01))(disc_input)                                \n",
    "            else:\n",
    "                 cnn = Conv2D(\n",
    "                        filters= nb_filters,\n",
    "                        kernel_size= filter_size,\n",
    "                        strides= strides,\n",
    "                        padding=\"same\",\n",
    "                        kernel_regularizer=l2(.01))(cnn) \n",
    "            \n",
    "            \n",
    "            cnn = Dropout(0.5)(cnn)\n",
    "            cnn = BatchNormalization(momentum= batch_norm_momentum)(cnn)\n",
    "            cnn = LeakyReLU(alpha=0.2)(cnn)\n",
    "\n",
    "        # transform 3D Matrix to a 1D Vector\n",
    "        cnn = Flatten()(cnn)\n",
    "\n",
    "        # Layer 6 - Output Layer\n",
    "        cnn = Dense(1, kernel_regularizer = l2(.01))(cnn)\n",
    "        disc_output = Activation('sigmoid', name='discriminator_output')(cnn)\n",
    "\n",
    "        # Model definition with Functional API\n",
    "        _discriminator_model = Model(disc_input, disc_output)\n",
    "        _d_optim = Adam(lr = dis_lr, beta_1 = dis_beta1)        \n",
    "        _discriminator_model.compile(loss='binary_crossentropy', optimizer=_d_optim, metrics=['accuracy'])\n",
    "        \n",
    "        return _discriminator_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = init_discriminator(input_shape, n_filters, filter_size, strides, dis_lr, dis_beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_generator(latent_shape, n_filters, filter_size, strides, gen_lr=2e-4, gen_beta1=0.5, batch_norm_momentum = 0.8):\n",
    "\n",
    "        # generator input of latent space vector Z, typically a 1D vector\n",
    "        gen_input = Input(shape= latent_shape, name='generator_input')\n",
    "\n",
    "        # layer 1 - high dimensional dense layer\n",
    "        cnn = Dense(512 * 4 * 4)(gen_input)\n",
    "        cnn = BatchNormalization(momentum= batch_norm_momentum)(cnn)\n",
    "        cnn = LeakyReLU(alpha=0.2)(cnn)\n",
    "        cnn = Reshape((4, 4, 512))(cnn)\n",
    "\n",
    "        # layer 2-5 - high dimensional dense layer\n",
    "        for nb_filters in n_filters:\n",
    "             cnn = Conv2DTranspose(\n",
    "                    filters     = nb_filters,\n",
    "                    kernel_size = filter_size,\n",
    "                    strides     = strides,\n",
    "                    padding     = 'same')(cnn)\n",
    "\n",
    "             # simple and works\n",
    "             cnn = UpSampling2D((2, 2))(cnn)\n",
    "             cnn = Conv2D(\n",
    "                        filters=nb_filters,\n",
    "                        kernel_size= filter_size,\n",
    "                        padding='same')(cnn)\n",
    "\n",
    "             cnn = BatchNormalization(momentum= batch_norm_momentum)(cnn)\n",
    "             cnn = LeakyReLU(alpha=0.2)(cnn)\n",
    "                \n",
    "\n",
    "        # layer 6 - Final convolution layer\n",
    "        cnn = Conv2D(1, kernel_size= filter_size, padding='same')(cnn)\n",
    "        gen_output = Activation('tanh', name='generator_output')(cnn)\n",
    "\n",
    "        _generator_model_model = Model(gen_input, gen_output)         \n",
    "        f_lr=2e-4 \n",
    "        f_beta1=0.5\n",
    "        _g_optim = Adam(lr= f_lr, beta_1= f_beta1)      \n",
    "        _generator_model_model.compile(loss='binary_crossentropy', optimizer=_g_optim)\n",
    "        return _generator_model_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user correct verrables\n",
    "generator_model = init_generator(latent_shape, n_filters, filter_size, strides, gen_lr, gen_beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_z(batch_size, latent_shape):\n",
    "        mu, sigma = 0, 0.4\n",
    "        lower, upper = -1, 1\n",
    "\n",
    "        return truncnorm.rvs(\n",
    "            (lower - mu) / sigma, (upper - mu) / sigma,\n",
    "            loc=mu,\n",
    "            scale=sigma,\n",
    "            size=(batch_size,  latent_shape[0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(generator_model, batch_size, latent_shape, verbose=0):\n",
    "        noise = generate_sample_z(batch_size, latent_shape)       \n",
    "\n",
    "        # We generate a batch of images with G\n",
    "        return generator_model.predict(noise, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fullgan(\n",
    "            generator_model,\n",
    "            discriminator_model,\n",
    "            input_shape=(64, 64, 1),\n",
    "            latent_shape=(100,),\n",
    "            n_filters=[512, 256, 128, 64],\n",
    "            filter_size=5,\n",
    "            strides=2,           \n",
    "            model_name=\"\",\n",
    "            outdir=\"output\",\n",
    "            stats_step_interval=100):\n",
    "    \n",
    "    print(\"Model Name: %s\" %  model_name)\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "            \n",
    "    gan_input = Input(shape=latent_shape)\n",
    "\n",
    "    # link the input of the GAN to the Generator\n",
    "    G_output =  generator_model(gan_input)\n",
    "\n",
    "    # For the combined model we will only train the generator => We do not want to backpropagate D while training G\n",
    "    discriminator_model.trainable = False\n",
    "\n",
    "    # we retrieve the output of the GAN\n",
    "    gan_output = discriminator_model(G_output)\n",
    "\n",
    "    # we construct a model out of it.\n",
    "    _fullgan_model = Model(gan_input, gan_output)\n",
    "    _fullgan_optim = Adam(lr= gen_lr, beta_1= gen_beta1)    \n",
    "    _fullgan_model.compile(loss='binary_crossentropy', optimizer=_fullgan_optim, metrics=['accuracy'])\n",
    "    return _fullgan_model;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: my_model\n"
     ]
    }
   ],
   "source": [
    "#todo user correct params\n",
    "fullgan_model = init_fullgan(\n",
    "                             generator_model,\n",
    "                             discriminator_model,\n",
    "                             input_shape, \n",
    "                             latent_shape, \n",
    "                             n_filters, \n",
    "                             filter_size, \n",
    "                             strides, \n",
    "                             model_name,\n",
    "                             output_dirname,\n",
    "                             stats_step_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator_model, generator_model,  train_generator, validation_generator):\n",
    "    \n",
    "  \n",
    "    batch_size = train_generator.batch_size\n",
    "        \n",
    "    n_steps = int(train_generator.samples / batch_size)\n",
    "    \n",
    "    #for epoch in range(epochs):\n",
    "    for epoch in range(1):\n",
    "        print('Epoch {} of {}\\n'.format(epoch + 1, epochs))\n",
    "        \n",
    "        progress_bar = Progbar(target=n_steps)\n",
    "        \n",
    "        tic = datetime.datetime.now()\n",
    "    \n",
    "        last_stats_idx_gen  = 0\n",
    "        last_stats_idx_disc = 0\n",
    "\n",
    "        epoch_gen_loss = list()\n",
    "        epoch_disc_loss = list()\n",
    "\n",
    "        epoch_gen_acc = list()\n",
    "        epoch_disc_acc = list()\n",
    "        \n",
    "        for step in range(n_steps):\n",
    "            \n",
    "            progress_bar.update(step + 1, force=True)            \n",
    "            \n",
    "            #generator\n",
    "            # rescaling images: pixel_values in [-1, 1]\n",
    "            image_batch = (train_generator.next().astype(np.float32) - 127.5) / 127.5          \n",
    "           \n",
    "\n",
    "            \n",
    "            #train step\n",
    "            discriminator_model.trainable = False\n",
    "            for l in discriminator_model.layers: l.trainable = False\n",
    "            \n",
    "            g_loss = 0.0\n",
    "            g_acc  = 0.0\n",
    "            \n",
    "           \n",
    "            # We train G twice, because D is trained twice at each step\n",
    "            for _ in range(2):\n",
    "                noise = generate_sample_z(batch_size, latent_shape)\n",
    "               \n",
    "                loss, acc = fullgan_model.train_on_batch(noise, np.ones(noise.shape[0]))\n",
    "       \n",
    "                g_loss = np.add(g_loss, loss)\n",
    "                g_acc  = np.add(g_acc, acc)\n",
    "                \n",
    "            g_loss *= 0.5\n",
    "            g_acc  *= 0.5       \n",
    "\n",
    "        \n",
    "            #discriminator\n",
    "            if g_acc >= d_acc_threshold:  # Preventing D to become too strong\n",
    "\n",
    "                discriminator_model.trainable = True\n",
    "                for l in discriminator_model.layers: l.trainable = True\n",
    "\n",
    "\n",
    "                generated_images = generate_samples(generator_model=generator_model, batch_size=batch_size, latent_shape=latent_shape, verbose=verbose)\n",
    "\n",
    "                d_loss_fake, d_acc_fake = discriminator_model.train_on_batch(\n",
    "                                                generated_images,\n",
    "                                                np.zeros(generated_images.shape[0]))\n",
    " \n",
    "                d_loss_real, d_acc_real = discriminator_model.train_on_batch(X, np.ones(X.shape[0]))\n",
    "\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                d_acc  = 0.5 * np.add(d_acc_real,  d_acc_fake)\n",
    " \n",
    "\n",
    "            else:\n",
    "                d_loss = None \n",
    "                d_acc  = None\n",
    "            \n",
    "            \n",
    "            if not d_loss is None:\n",
    "                epoch_disc_loss.append(d_loss)\n",
    "                epoch_disc_acc.append(d_acc)\n",
    "\n",
    "            epoch_gen_loss.append(g_loss)\n",
    "            epoch_gen_acc.append(g_acc)\n",
    "            \n",
    "            generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
    "            discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n",
    "            generator_train_acc = np.mean(np.array(epoch_gen_acc), axis=0)\n",
    "            discriminator_train_acc = np.mean(np.array(epoch_disc_acc), axis=0)\n",
    "            \n",
    "            print(\"generator_train_loss {}\".forma(generator_train_loss))\n",
    "            print(\"discriminator_train_loss {}\".format(discriminator_train_loss))\n",
    "            print(\"generator_train_acc {}\".generator_train_acc)\n",
    "            print(\"discriminator_train_acc {}\".format(discriminator_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1\n",
      "\n",
      "\r",
      "1/3 [=========>....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "train(discriminator_model, generator_model, train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_defects(discriminator_model, generator_model,  validation_generator, verbose=1):\n",
    "\n",
    "        total_samples = validation_generator.samples\n",
    "        batch_size = validation_generator.batch_size\n",
    "\n",
    "        results = list()\n",
    "        labels = list()\n",
    "\n",
    "        if (verbose != 0):\n",
    "            progress_bar = Progbar(target=total_samples)\n",
    "\n",
    "        for _ in range(np.ceil(total_samples / batch_size).astype(np.int32)):\n",
    "\n",
    "            image_batch, lbls = validation_generator.next()\n",
    "\n",
    "            labels = np.append(labels, lbls.reshape(lbls.shape[0]))\n",
    "            image_batch = (image_batch.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "            tmp_rslt = discriminator_model.predict(\n",
    "                x=image_batch,\n",
    "                batch_size=image_batch.shape[0],\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            if (verbose != 0):\n",
    "                progress_bar.add(image_batch.shape[0])\n",
    "\n",
    "            results = np.append(results, tmp_rslt.reshape(tmp_rslt.shape[0]))\n",
    "\n",
    "        results = [1 if x >= 0.5 else 0 for x in results]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, results).ravel()\n",
    "\n",
    "        #################### NON DEFECT SITUATIONS ####################\n",
    "\n",
    "        # Probability of Detecting a Non-Defect: (tp / (tp + fn))\n",
    "        if ((tp + fn) != 0):\n",
    "            recall = tp / (tp + fn)\n",
    "        else:\n",
    "            recall = 0.0\n",
    "\n",
    "        # Probability of Correctly Detecting a Non-Defect: (tp / (tp + fp))\n",
    "\n",
    "        if ((tp + fp) != 0):\n",
    "            precision = tp / (tp + fp)\n",
    "        else:\n",
    "            precision = 0.0\n",
    "\n",
    "        ###################### DEFECT SITUATIONS ######################\n",
    "\n",
    "        # Probability of Detecting a Defect: (tn / (tn + fp))\n",
    "        if ((tn + fp) != 0):\n",
    "            specificity = tn / (tn + fp)\n",
    "        else:\n",
    "            specificity = 0.0\n",
    "\n",
    "        # Probability of Correctly Detecting a Defect: (tn / (tn + fn))\n",
    "        if ((tn + fn) != 0):\n",
    "            negative_predictive_value = tn / (tn + fn)\n",
    "        else:\n",
    "            negative_predictive_value = 0.0\n",
    "\n",
    "        return precision, recall, specificity, negative_predictive_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, specificity, negative_predictive_value = detect_defects(discriminator_model, generator_model, validation_generator)\n",
    "\n",
    "print()\n",
    "print(\"Probability of Detecting a Non-Defect             => Recall      (tp / (tp + fn)):\", recall)\n",
    "print(\"Probability of Correctly Detecting a Non-Defect   => Precision   (tp / (tp + fp)):\", precision)\n",
    "print(\"Probability of Detecting a Defect                 => Specificity (tn / (tn + fp)):\", specificity)\n",
    "print(\"Probability of Correctly Detecting a Defect       => NPV         (tn / (tn + fn)):\", negative_predictive_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
